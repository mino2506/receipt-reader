"use client";

import type { CV } from "@/types/opencv";
import { useEffect, useRef } from "react";

interface CameraPreviewCanvasProps {
	cv: CV | null;
	videoRef: React.RefObject<HTMLVideoElement | null>;
	rotation?: number; // default 0
	isActive: boolean;
	className?: string;
	onError: (error: string) => void;
}

export function CameraPreviewCanvas({
	cv,
	videoRef,
	rotation: rotationInput = 0,
	isActive: isActiveInput,
	className = "",
	onError,
}: CameraPreviewCanvasProps) {
	const rotationRef = useRef(rotationInput);
	const isActiveRef = useRef(isActiveInput);
	const canvasRef = useRef<HTMLCanvasElement>(null);

	useEffect(() => {
		if (!cv || !videoRef.current || !canvasRef.current) return;

		// ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ£å†…ã§ã®å‡çµã®å›é¿ç”¨
		isActiveRef.current = isActiveInput;
		rotationRef.current = rotationInput;

		const isActive = isActiveRef.current;
		const rotation = rotationRef.current;
		const video = videoRef.current;
		const canvas = canvasRef.current;

		let animationId: number;

		// Main ãƒ«ãƒ¼ãƒ—: ã‚«ãƒ¡ãƒ©æ˜ åƒã‚’æç”»ã™ã‚‹
		const render = () => {
			console.log("renderLoop");
			if (!isActive) return;
			if (video.readyState < 2) {
				animationId = requestAnimationFrame(render);
				return;
			}

			const width = video.videoWidth;
			const height = video.videoHeight;

			const cap = new cv.VideoCapture(video);
			const src = new cv.Mat(height, width, cv.CV_8UC4);
			const dst = new cv.Mat(
				rotation % 180 === 0 ? height : width,
				rotation % 180 === 0 ? width : height,
				cv.CV_8UC4,
			);

			cap.read(src);

			const deg = ((rotation % 360) + 360) % 360;
			switch (deg) {
				case 0:
					src.copyTo(dst);
					break;
				case 90:
					cv.rotate(src, dst, cv.ROTATE_90_CLOCKWISE);
					break;
				case 180:
					cv.rotate(src, dst, cv.ROTATE_180);
					break;
				case 270:
					cv.rotate(src, dst, cv.ROTATE_90_COUNTERCLOCKWISE);
					break;
				default:
					src.copyTo(dst);
					console.warn("Unsupported rotation:", render);
			}

			canvas.width = dst.cols;
			canvas.height = dst.rows;

			const normalized = preprocessForOcr(cv, dst);

			cv.imshow(canvas, normalized);

			normalized.delete;
			src.delete();
			dst.delete();

			animationId = requestAnimationFrame(render);
		};

		const handleMeta = () => {
			if (isActiveInput) {
				// videoè¦ç´ ã‚’å…ƒã®æ˜ åƒã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
				video.width = video.videoWidth;
				video.height = video.videoHeight;

				try {
					render();
				} catch (e) {
					const msg = e instanceof Error ? e.message : "ä¸æ˜ã®ã‚¨ãƒ©ãƒ¼";
					console.error(msg);
					onError(msg);
				}
			}
		};

		video.addEventListener("loadedmetadata", handleMeta);

		return () => {
			cancelAnimationFrame(animationId);
			video.removeEventListener("loadedmetadata", handleMeta);
		};
	}, [cv, isActiveInput, rotationInput, videoRef, onError]);

	return (
		<>
			<canvas
				ref={canvasRef}
				className={`w-full h-auto max-h-[75vh] object-contain border ${className}`}
			/>
		</>
	);
}

import type { Mat } from "@/types/opencv";

interface PreprocessOptions {
	morphologyLimit?: number;
	tileGridSize?: number;
	adaptiveBlockSize?: number;
	adaptiveC?: number;
	morphologyLimitOpen?: number;
	morphologyLimitClose?: number;
	morphologyLimitFinish?: number;
	medianLimit: number;
}

/**
 * OCR å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
 * å‘¼ã³å‡ºã—å…ƒã§ .delete() ã‚’å¿˜ã‚Œã‚‹ãªï¼
 * @param srcColor Mat (RGBA) â€” å…¥åŠ›ã‚«ãƒ©ãƒ¼ç”»åƒ
 * @param cv OpenCV.js CV ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
 * @returns äºŒå€¤åŒ–å¾Œã® Mat
 */
function preprocessForOcr(cv: CV, src: Mat, options?: PreprocessOptions): Mat {
	const {
		morphologyLimit = 2.0,
		tileGridSize = 6,
		adaptiveBlockSize = 11,
		adaptiveC = 2,
		morphologyLimitOpen,
		morphologyLimitClose,
		morphologyLimitFinish,
		medianLimit = 3,
	} = options || {};

	// ã“ã“ã§ä½œã‚‹MatãŸã¡ã‚’å…¨éƒ¨åˆæœŸåŒ–
	const gray = new cv.Mat();
	const enhanced = new cv.Mat();
	const bin = new cv.Mat();
	const denoised = new cv.Mat();
	const clahe = new cv.CLAHE(2.0, new cv.Size(tileGridSize, tileGridSize));

	const open = morphologyLimitOpen ?? morphologyLimit;
	const close = morphologyLimitClose ?? morphologyLimit;
	const finish = morphologyLimitFinish ?? morphologyLimit;
	const kernelOpen = cv.getStructuringElement(
		cv.MORPH_RECT,
		new cv.Size(open, open),
	);
	const kernelClose = cv.getStructuringElement(
		cv.MORPH_RECT,
		new cv.Size(close, close),
	);
	const kernelFinish = cv.getStructuringElement(
		cv.MORPH_RECT,
		new cv.Size(finish, finish),
	);

	try {
		// 1. ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«åŒ–
		cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

		// 2. CLAHE: é©å¿œãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å¹³å¦åŒ–
		clahe.apply(gray, enhanced);

		// cv.bilateralFilter(gray, denoised, 9, 75, 75);

		// 3. é©å¿œçš„äºŒå€¤åŒ–
		cv.adaptiveThreshold(
			enhanced,
			bin,
			255,
			cv.ADAPTIVE_THRESH_GAUSSIAN_C,
			cv.THRESH_BINARY,
			adaptiveBlockSize,
			adaptiveC,
		);

		// 4. å½¢æ…‹å­¦çš„å¤‰æ›ï¼ˆOPEN -> CLOSEï¼‰
		cv.morphologyEx(bin, bin, cv.MORPH_OPEN, kernelOpen);
		cv.morphologyEx(bin, bin, cv.MORPH_CLOSE, kernelClose);

		// 5. ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿
		cv.medianBlur(bin, denoised, medianLimit);

		// 6. æœ€çµ‚Morphologyï¼ˆã‚‚ã†ä¸€åº¦OPENï¼‰
		cv.morphologyEx(bin, denoised, cv.MORPH_OPEN, kernelFinish);

		// ğŸ”¥ denoisedã ã‘å‘¼ã³å‡ºã—å…ƒã«æ¸¡ã™
		return denoised.clone(); // å‘¼ã³å‡ºã—å…ƒã§ delete() ã—ã¦ã­
	} catch (e) {
		if (e instanceof Error) {
			console.error(e.message);
			throw e;
		}
		console.error("Unknown error", e);
		throw new Error("Unknown error during OpenCV processing");
	} finally {
		// ğŸ¯ ä¾‹å¤–ãŒå‡ºã¦ã‚‚å¿…ãšdelete
		gray.delete();
		enhanced.delete();
		bin.delete();
		denoised.delete();
		clahe.delete();
		kernelOpen.delete();
		kernelClose.delete();
		kernelFinish.delete();
	}
}

interface DeskewOptions {
	cannyThreshold1?: number;
	cannyThreshold2?: number;
}

/**
 * deskewï¼ˆå‚¾ãè£œæ­£ï¼‰å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
 * å‘¼ã³å‡ºã—å…ƒã§ .delete() ã‚’å¿˜ã‚Œã‚‹ãªï¼
 * @param srcColor Mat (RGBA) â€” å…¥åŠ›ã‚«ãƒ©ãƒ¼ç”»åƒ
 * @param cv OpenCV.js CV ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
 * @param options - ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆCannyã®é–¾å€¤ãªã©ï¼‰
 * @returns å‚¾ãè£œæ­£å¾Œã®ã‚«ãƒ©ãƒ¼ Mat
 */
// function preprocessForDeskew(
// 	cv: CV,
// 	srcColor: Mat,
// 	options?: DeskewOptions,
// ): Mat {
// 	const { cannyThreshold1 = 50, cannyThreshold2 = 150 } = options || {};

// 	// MatãŸã¡ã‚’åˆæœŸåŒ–
// 	const gray = new cv.Mat();
// 	const binary = new cv.Mat();
// 	const edges = new cv.Mat();
// 	const contours = new cv.MatVector();
// 	const hierarchy = new cv.Mat();
// 	const deskewed = new cv.Mat();

// 	try {
// 		// 1. ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«åŒ–
// 		cv.cvtColor(srcColor, gray, cv.COLOR_RGBA2GRAY);

// 		// 2. äºŒå€¤åŒ–ï¼ˆå˜ç´”ãªã—ãã„å€¤ã€ä»®ï¼‰
// 		cv.threshold(gray, binary, 127, 255, cv.THRESH_BINARY);

// 		// 3. ã‚¨ãƒƒã‚¸æ¤œå‡ºï¼ˆCannyï¼‰
// 		cv.Canny(binary, edges, cannyThreshold1, cannyThreshold2);

// 		// 4. è¼ªéƒ­æ¤œå‡º
// 		cv.findContours(
// 			edges,
// 			contours,
// 			hierarchy,
// 			cv.RETR_EXTERNAL,
// 			cv.CHAIN_APPROX_SIMPLE,
// 		);

// 		if (contours.size() === 0) {
// 			throw new Error("No contours found for deskewing");
// 		}

// 		// 5. æœ€å¤§è¼ªéƒ­ã‚’å–å¾—
// 		let largestContour = contours.get(0);
// 		let maxArea = cv.contourArea(largestContour);

// 		for (let i = 1; i < contours.size(); i++) {
// 			const cnt = contours.get(i);
// 			const area = cv.contourArea(cnt);
// 			if (area > maxArea) {
// 				largestContour = cnt;
// 				maxArea = area;
// 			}
// 		}

// 		// 6. å¤–æ¥çŸ©å½¢ã‹ã‚‰è§’åº¦ã‚’å–å¾—
// 		const rotatedRect = cv.minAreaRect(largestContour);
// 		let angle = rotatedRect.angle;
// 		if (angle < -45) {
// 			angle += 90;
// 		}

// 		// 7. å›è»¢è£œæ­£ï¼ˆdeskewï¼‰
// 		const center = new cv.Point(srcColor.cols / 2, srcColor.rows / 2);
// 		const M = cv.getRotationMatrix2D(center, angle, 1.0);
// 		cv.warpAffine(
// 			srcColor,
// 			deskewed,
// 			M,
// 			new cv.Size(srcColor.cols, srcColor.rows),
// 			cv.INTER_LINEAR,
// 			cv.BORDER_CONSTANT,
// 			new cv.Scalar(),
// 		);

// 		M.delete();

// 		// ğŸ”¥ deskewedã ã‘å‘¼ã³å‡ºã—å…ƒã«æ¸¡ã™
// 		return deskewed.clone(); // å‘¼ã³å‡ºã—å…ƒã§ delete() ã—ã¦ã­
// 	} catch (e) {
// 		if (e instanceof Error) {
// 			console.error(e.message);
// 			throw e;
// 		}
// 		console.error("Unknown error", e);
// 		throw new Error("Unknown error during OpenCV deskewing");
// 	} finally {
// 		// ğŸ¯ ä¾‹å¤–ãŒå‡ºã¦ã‚‚å¿…ãšdelete
// 		gray.delete();
// 		binary.delete();
// 		edges.delete();
// 		contours.delete();
// 		hierarchy.delete();
// 		deskewed.delete();
// 	}
// }
